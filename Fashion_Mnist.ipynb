{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-1dwB7rjWN"
      },
      "source": [
        "# Work with tensorflow to design neural network to recognize clothing item  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu01KFVUNMSy"
      },
      "outputs": [],
      "source": [
        "# imoport libraries we will use it \n",
        "import tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89tujeYANyhg"
      },
      "outputs": [],
      "source": [
        "# to access built-in dataset that include thousands of images \n",
        "dataset = tensorflow.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gn2FoNvOAtK"
      },
      "outputs": [],
      "source": [
        "# we will load the data and split it to training images and test images \n",
        "# we split the data into train and set to reduce the number of new concepts the model need to learn \n",
        "(training_images , training_labels),(test_images,test_lables) = dataset.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49xCnmDJOQ_i"
      },
      "outputs": [],
      "source": [
        "# the images in grayscale have value between 0 and 255 and we divide them by 255 to ensure that every pixels will be between 0 and 1\n",
        "# this concept called Normalizing the image\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images /255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5x4QqkxqOWEo"
      },
      "outputs": [],
      "source": [
        "# the first layer \"Flattern\" isnt layer of neurons , it is consider as input layer specification \n",
        "# the second layer \"Dense\" is layer of neurons between input and output and using activation function this code will execute on each neuron in the layer , \n",
        "# \"relu\" is function that return value if it's more than 0\n",
        "# the third layer another \"Dense\" which is output layer we have only 10 neurons because we only have 10 classes . which mean we will combine the output of previous layer to match these 10 classes .\n",
        "# \"softmax\" is function used to determine the highest value\n",
        "model = tensorflow.keras.models.Sequential([\n",
        "    tensorflow.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tensorflow.keras.layers.Dense(128,activation=tensorflow.nn.relu),\n",
        "    tensorflow.keras.layers.Dense(10,activation=tensorflow.nn.softmax),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQSV2AM0OnwT"
      },
      "outputs": [],
      "source": [
        "# the \"adam\" optimizer is an evolution of sdg (stochastic gradient descent) optimizer that shows faster and more efficient\n",
        "# the \"spare categorical\" loss , we want to predict between 1 to 10 category that we have\n",
        "# using accuracy percentage to determine metrics of our model training \n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlHXETFzPRBZ",
        "outputId": "d3714c9f-d101-4c69-b781-c8f1751df166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.5008 - accuracy: 0.8245\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3731 - accuracy: 0.8665\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3375 - accuracy: 0.8764\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3113 - accuracy: 0.8868\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2933 - accuracy: 0.8923\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2791 - accuracy: 0.8971\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2659 - accuracy: 0.9017\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2542 - accuracy: 0.9068\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2453 - accuracy: 0.9085\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2382 - accuracy: 0.9118\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2307 - accuracy: 0.9138\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2216 - accuracy: 0.9183\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2151 - accuracy: 0.9204\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2100 - accuracy: 0.9212\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2038 - accuracy: 0.9235\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1979 - accuracy: 0.9262\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1911 - accuracy: 0.9287\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1864 - accuracy: 0.9291\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1816 - accuracy: 0.9327\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1776 - accuracy: 0.9331\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1728 - accuracy: 0.9354\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1677 - accuracy: 0.9371\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1647 - accuracy: 0.9377\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1619 - accuracy: 0.9396\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1576 - accuracy: 0.9398\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1543 - accuracy: 0.9418\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1509 - accuracy: 0.9436\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1479 - accuracy: 0.9447\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1443 - accuracy: 0.9453\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1418 - accuracy: 0.9471\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1398 - accuracy: 0.9470\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1360 - accuracy: 0.9486\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1323 - accuracy: 0.9506\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9493\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1287 - accuracy: 0.9512\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1266 - accuracy: 0.9527\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1236 - accuracy: 0.9530\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1207 - accuracy: 0.9541\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1210 - accuracy: 0.9550\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1153 - accuracy: 0.9572\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1131 - accuracy: 0.9582\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1132 - accuracy: 0.9574\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9584\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1077 - accuracy: 0.9593\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1064 - accuracy: 0.9592\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9614\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1033 - accuracy: 0.9606\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1024 - accuracy: 0.9620\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0994 - accuracy: 0.9628\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0987 - accuracy: 0.9621\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8af6f6730>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(training_images,training_labels,epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Krkfpxw3PfPI",
        "outputId": "5808428e-8b0a-421d-c13c-b807b794ca3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.8840\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.513889729976654, 0.8840000033378601]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_images,test_lables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VFUThyzreIHd",
        "outputId": "0c6577f3-56a1-4c01-8daa-19618d161b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr+vAh4QzUVoFXd/XWTyUT"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}